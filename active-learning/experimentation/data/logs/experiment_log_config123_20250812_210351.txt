ğŸ“ Logging started - Output will be saved to: /Users/lucasbraga/Documents/GitHub/active-learning/active-learning/experimentation/data/logs/experiment_log_config123_20250812_210351.txt
â° Timestamp: 2025-08-12 21:03:51
================================================================================
ğŸ¦ Bank Marketing Dataset - Active Learning vs Passive Learning Comparison
================================================================================
Dataset: UCI Bank Marketing (Portuguese Bank)
Target: Whether customer subscribed to term deposit (yes/no)
Features: Age, job, marital status, education, balance, housing, loan, etc.
================================================================================
ğŸš€ ENHANCEMENT: Using Logistic Regression WITHOUT Regularization
ğŸ¯ GOAL: Test if lack of regularization was the limiting factor
ğŸ”§ Model: LogisticRegression() with DEFAULT parameters
================================================================================
ğŸ“Š Dataset Size: 45,211 rows (Full dataset)
ğŸ“Š Expected splits: ~36,169 train, ~9,042 test
================================================================================
Model Configuration:
  Model Type: Logistic Regression (NO regularization)
  Parameters: DEFAULT (C=1.0, penalty='l2', but C=1.0 means no penalty)

Plot Configuration:
  Show Plots: False

Experiment Configuration:
  Initial samples: 300
  Initial strategy: diversity
  Batch size: 68
  Iterations: 11
  Strategies: ['uncertainty', 'uncertainty', 'diversity', 'uncertainty', 'diversity', 'uncertainty', 'uncertainty', 'diversity', 'uncertainty', 'uncertainty', 'qbc']
  âœ“ Initial strategy 'diversity' is valid

ğŸ“Š Using FULL bank dataset (45,211 rows)
âœ… Loading bank dataset from: /Users/lucasbraga/Documents/GitHub/active-learning/active-learning/data/uci_dataset_00222_bank/bank-full.csv
Feature type: Numerical age and balance
Loading and splitting data...
Dataset shape: (45211, 17)
Cleaning and preprocessing bank dataset...
ğŸ§¹ Cleaning and preprocessing bank dataset...
  ğŸ“Š Original dataset shape: (45211, 17)
  ğŸ” Missing values in original data:
    No missing values found
  âœ“ Using numerical age features (normalized + squared)
  âœ“ Using numerical balance features (log-transformed + normalized)
  ğŸ” Checking for NaN values after preprocessing...
    Found NaN values in columns:
balance_norm    1
dtype: int64
    ğŸ§¹ Filling NaN values...
      balance_norm: filled with median (-0.3586)
  ğŸ”§ Applying global feature standardization...
    ğŸ”’ Using sorted column order for reproducibility: ['age_norm', 'age_squared', 'balance_norm', 'campaign', 'default_bool', 'duration', 'housing_bool', 'loan_bool', 'month_cos', 'month_sin']
    âœ“ Standardized 10 numerical features
    ğŸ”’ Standardization parameters:
      Mean values: {'age_norm': 2.0116668549090447e-16, 'age_squared': 0.9999778814890183, 'balance_norm': -7.93146638145373e-06, 'campaign': 2.763840658246887, 'default_bool': 0.018026586450200173, 'duration': 258.1630797814691, 'housing_bool': 0.5558381809736569, 'loan_bool': 0.16022649355245405, 'month_cos': -0.4703013950820929, 'month_sin': 0.01844905737733411}
      Scale values: {'age_norm': 0.999988940683355, 'age_squared': 1.5229247271132622, 'balance_norm': 0.9999793033137726, 'campaign': 3.097986621285248, 'default_bool': 0.133047467586398, 'duration': 257.5249641835511, 'housing_bool': 0.4968723151329254, 'loan_bool': 0.3668159815443426, 'month_cos': 0.6348584209990016, 'month_sin': 0.6127242571927273}
  ğŸ“Š Final dataset shape: (45211, 31)
  ğŸ¯ Target distribution: {0: 39922, 1: 5289}
Features after preprocessing: 31
Label distribution: {0: 39922, 1: 5289}
Train set: 36168 samples
Test set: 9043 samples
Label distribution in train: {0: 31937, 1: 4231}

================================================================================
RUNNING 10 EXPERIMENTS FOR STATISTICAL SIGNIFICANCE
================================================================================

--- Run 1/10 ---

============================================================
ACTIVE LEARNING EXPERIMENT
============================================================
  Using diversity sampling for initial pool...
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3562, Accuracy: 0.8716
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3481, Accuracy: 0.8944
Selected 68 samples using uncertainty sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3951, Accuracy: 0.8976
Selected 68 samples using diversity sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4189, Accuracy: 0.8995
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4330, Accuracy: 0.8983
Selected 68 samples using diversity sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4537, Accuracy: 0.8998
Selected 68 samples using uncertainty sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4520, Accuracy: 0.8991
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4515, Accuracy: 0.8976
Selected 68 samples using diversity sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4641, Accuracy: 0.8988
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4785, Accuracy: 0.8978
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4896, Accuracy: 0.8983

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4774, Accuracy: 0.8966

============================================================
PASSIVE LEARNING EXPERIMENT
============================================================
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4647, Accuracy: 0.8124
Selected 68 samples using random sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4837, Accuracy: 0.8200
Selected 68 samples using random sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4776, Accuracy: 0.8197
Selected 68 samples using random sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4838, Accuracy: 0.8265
Selected 68 samples using random sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4757, Accuracy: 0.8199
Selected 68 samples using random sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4634, Accuracy: 0.8095
Selected 68 samples using random sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4720, Accuracy: 0.8083
Selected 68 samples using random sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4794, Accuracy: 0.8114
Selected 68 samples using random sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4792, Accuracy: 0.8101
Selected 68 samples using random sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4841, Accuracy: 0.8159
Selected 68 samples using random sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4902, Accuracy: 0.8166

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4940, Accuracy: 0.8174
Run 1 completed - Active F1: 0.4774, Passive F1: 0.4940

--- Run 2/10 ---

============================================================
ACTIVE LEARNING EXPERIMENT
============================================================
  Using diversity sampling for initial pool...
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3907, Accuracy: 0.8659
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4045, Accuracy: 0.8824
Selected 68 samples using uncertainty sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4034, Accuracy: 0.8920
Selected 68 samples using diversity sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4048, Accuracy: 0.8907
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4387, Accuracy: 0.8925
Selected 68 samples using diversity sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4444, Accuracy: 0.8922
Selected 68 samples using uncertainty sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4505, Accuracy: 0.8941
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4606, Accuracy: 0.8893
Selected 68 samples using diversity sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4576, Accuracy: 0.8869
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4747, Accuracy: 0.8868
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4761, Accuracy: 0.8878

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4871, Accuracy: 0.8901

============================================================
PASSIVE LEARNING EXPERIMENT
============================================================
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4826, Accuracy: 0.8236
Selected 68 samples using random sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4797, Accuracy: 0.8207
Selected 68 samples using random sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4780, Accuracy: 0.8213
Selected 68 samples using random sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4801, Accuracy: 0.8228
Selected 68 samples using random sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4904, Accuracy: 0.8204
Selected 68 samples using random sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5060, Accuracy: 0.8280
Selected 68 samples using random sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5041, Accuracy: 0.8249
Selected 68 samples using random sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5035, Accuracy: 0.8239
Selected 68 samples using random sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5092, Accuracy: 0.8262
Selected 68 samples using random sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5140, Accuracy: 0.8296
Selected 68 samples using random sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5157, Accuracy: 0.8297

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.5086, Accuracy: 0.8272
Run 2 completed - Active F1: 0.4871, Passive F1: 0.5086

--- Run 3/10 ---

============================================================
ACTIVE LEARNING EXPERIMENT
============================================================
  Using diversity sampling for initial pool...
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3516, Accuracy: 0.8542
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3698, Accuracy: 0.8916
Selected 68 samples using uncertainty sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4211, Accuracy: 0.8966
Selected 68 samples using diversity sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4145, Accuracy: 0.8954
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4271, Accuracy: 0.8947
Selected 68 samples using diversity sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4278, Accuracy: 0.8920
Selected 68 samples using uncertainty sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4440, Accuracy: 0.8951
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4464, Accuracy: 0.8958
Selected 68 samples using diversity sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4533, Accuracy: 0.8973
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4613, Accuracy: 0.8970
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4693, Accuracy: 0.8959

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4782, Accuracy: 0.8979

============================================================
PASSIVE LEARNING EXPERIMENT
============================================================
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4889, Accuracy: 0.8283
Selected 68 samples using random sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4908, Accuracy: 0.8239
Selected 68 samples using random sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5103, Accuracy: 0.8355
Selected 68 samples using random sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5091, Accuracy: 0.8358
Selected 68 samples using random sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5124, Accuracy: 0.8392
Selected 68 samples using random sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5190, Accuracy: 0.8358
Selected 68 samples using random sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5180, Accuracy: 0.8372
Selected 68 samples using random sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5192, Accuracy: 0.8372
Selected 68 samples using random sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5145, Accuracy: 0.8356
Selected 68 samples using random sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5201, Accuracy: 0.8385
Selected 68 samples using random sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5198, Accuracy: 0.8361

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.5183, Accuracy: 0.8366
Run 3 completed - Active F1: 0.4782, Passive F1: 0.5183

--- Run 4/10 ---

============================================================
ACTIVE LEARNING EXPERIMENT
============================================================
  Using diversity sampling for initial pool...
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3436, Accuracy: 0.7813
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4077, Accuracy: 0.8763
Selected 68 samples using uncertainty sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4423, Accuracy: 0.8871
Selected 68 samples using diversity sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4457, Accuracy: 0.8879
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4413, Accuracy: 0.8908
Selected 68 samples using diversity sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4477, Accuracy: 0.8898
Selected 68 samples using uncertainty sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4663, Accuracy: 0.8905
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4609, Accuracy: 0.8894
Selected 68 samples using diversity sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4783, Accuracy: 0.8918
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4788, Accuracy: 0.8911
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4699, Accuracy: 0.8905

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4926, Accuracy: 0.8973

============================================================
PASSIVE LEARNING EXPERIMENT
============================================================
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4226, Accuracy: 0.7870
Selected 68 samples using random sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4347, Accuracy: 0.7835
Selected 68 samples using random sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4545, Accuracy: 0.7976
Selected 68 samples using random sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4544, Accuracy: 0.7939
Selected 68 samples using random sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4507, Accuracy: 0.7860
Selected 68 samples using random sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4608, Accuracy: 0.7920
Selected 68 samples using random sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4596, Accuracy: 0.7900
Selected 68 samples using random sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4610, Accuracy: 0.7906
Selected 68 samples using random sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4711, Accuracy: 0.7949
Selected 68 samples using random sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4715, Accuracy: 0.7973
Selected 68 samples using random sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4739, Accuracy: 0.7996

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4877, Accuracy: 0.8048
Run 4 completed - Active F1: 0.4926, Passive F1: 0.4877

--- Run 5/10 ---

============================================================
ACTIVE LEARNING EXPERIMENT
============================================================
  Using diversity sampling for initial pool...
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3643, Accuracy: 0.7737
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4303, Accuracy: 0.8712
Selected 68 samples using uncertainty sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4429, Accuracy: 0.8880
Selected 68 samples using diversity sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4580, Accuracy: 0.8884
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4687, Accuracy: 0.8922
Selected 68 samples using diversity sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4746, Accuracy: 0.8926
Selected 68 samples using uncertainty sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4726, Accuracy: 0.8911
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4875, Accuracy: 0.8898
Selected 68 samples using diversity sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4844, Accuracy: 0.8879
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4890, Accuracy: 0.8908
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4874, Accuracy: 0.8907

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4909, Accuracy: 0.8913

============================================================
PASSIVE LEARNING EXPERIMENT
============================================================
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4709, Accuracy: 0.8077
Selected 68 samples using random sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4960, Accuracy: 0.8174
Selected 68 samples using random sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5027, Accuracy: 0.8236
Selected 68 samples using random sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5085, Accuracy: 0.8282
Selected 68 samples using random sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5073, Accuracy: 0.8268
Selected 68 samples using random sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5095, Accuracy: 0.8249
Selected 68 samples using random sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5048, Accuracy: 0.8221
Selected 68 samples using random sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4902, Accuracy: 0.8091
Selected 68 samples using random sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4992, Accuracy: 0.8164
Selected 68 samples using random sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4983, Accuracy: 0.8168
Selected 68 samples using random sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4998, Accuracy: 0.8193

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.5002, Accuracy: 0.8188
Run 5 completed - Active F1: 0.4909, Passive F1: 0.5002

--- Run 6/10 ---

============================================================
ACTIVE LEARNING EXPERIMENT
============================================================
  Using diversity sampling for initial pool...
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3496, Accuracy: 0.8786
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3528, Accuracy: 0.8915
Selected 68 samples using uncertainty sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4044, Accuracy: 0.8962
Selected 68 samples using diversity sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4155, Accuracy: 0.8958
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4228, Accuracy: 0.8966
Selected 68 samples using diversity sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4374, Accuracy: 0.8969
Selected 68 samples using uncertainty sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4527, Accuracy: 0.8984
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4476, Accuracy: 0.8973
Selected 68 samples using diversity sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4562, Accuracy: 0.8978
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4658, Accuracy: 0.8976
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4818, Accuracy: 0.8977

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4707, Accuracy: 0.8963

============================================================
PASSIVE LEARNING EXPERIMENT
============================================================
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4972, Accuracy: 0.8502
Selected 68 samples using random sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4988, Accuracy: 0.8528
Selected 68 samples using random sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5002, Accuracy: 0.8464
Selected 68 samples using random sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4998, Accuracy: 0.8401
Selected 68 samples using random sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4965, Accuracy: 0.8326
Selected 68 samples using random sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5082, Accuracy: 0.8392
Selected 68 samples using random sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5042, Accuracy: 0.8349
Selected 68 samples using random sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5140, Accuracy: 0.8374
Selected 68 samples using random sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5050, Accuracy: 0.8296
Selected 68 samples using random sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5059, Accuracy: 0.8261
Selected 68 samples using random sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5045, Accuracy: 0.8268

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.5010, Accuracy: 0.8275
Run 6 completed - Active F1: 0.4707, Passive F1: 0.5010

--- Run 7/10 ---

============================================================
ACTIVE LEARNING EXPERIMENT
============================================================
  Using diversity sampling for initial pool...
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4337, Accuracy: 0.8737
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4455, Accuracy: 0.8826
Selected 68 samples using uncertainty sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4722, Accuracy: 0.8909
Selected 68 samples using diversity sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4564, Accuracy: 0.8880
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4520, Accuracy: 0.8911
Selected 68 samples using diversity sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4636, Accuracy: 0.8909
Selected 68 samples using uncertainty sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4820, Accuracy: 0.8927
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4886, Accuracy: 0.8918
Selected 68 samples using diversity sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4846, Accuracy: 0.8915
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4997, Accuracy: 0.8940
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5114, Accuracy: 0.8936

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.5060, Accuracy: 0.8948

============================================================
PASSIVE LEARNING EXPERIMENT
============================================================
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5316, Accuracy: 0.8533
Selected 68 samples using random sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5094, Accuracy: 0.8333
Selected 68 samples using random sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5143, Accuracy: 0.8378
Selected 68 samples using random sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5130, Accuracy: 0.8338
Selected 68 samples using random sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5165, Accuracy: 0.8320
Selected 68 samples using random sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5084, Accuracy: 0.8305
Selected 68 samples using random sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5067, Accuracy: 0.8264
Selected 68 samples using random sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5117, Accuracy: 0.8298
Selected 68 samples using random sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5076, Accuracy: 0.8254
Selected 68 samples using random sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5105, Accuracy: 0.8287
Selected 68 samples using random sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5125, Accuracy: 0.8304

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.5158, Accuracy: 0.8327
Run 7 completed - Active F1: 0.5060, Passive F1: 0.5158

--- Run 8/10 ---

============================================================
ACTIVE LEARNING EXPERIMENT
============================================================
  Using diversity sampling for initial pool...
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3710, Accuracy: 0.7985
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4275, Accuracy: 0.8815
Selected 68 samples using uncertainty sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4650, Accuracy: 0.8922
Selected 68 samples using diversity sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4637, Accuracy: 0.8907
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4799, Accuracy: 0.8945
Selected 68 samples using diversity sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4722, Accuracy: 0.8937
Selected 68 samples using uncertainty sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4822, Accuracy: 0.8955
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4792, Accuracy: 0.8945
Selected 68 samples using diversity sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4860, Accuracy: 0.8959
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4980, Accuracy: 0.8963
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5033, Accuracy: 0.8949

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.5145, Accuracy: 0.8963

============================================================
PASSIVE LEARNING EXPERIMENT
============================================================
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4741, Accuracy: 0.8163
Selected 68 samples using random sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4862, Accuracy: 0.8221
Selected 68 samples using random sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4876, Accuracy: 0.8146
Selected 68 samples using random sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5054, Accuracy: 0.8222
Selected 68 samples using random sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5063, Accuracy: 0.8280
Selected 68 samples using random sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5076, Accuracy: 0.8257
Selected 68 samples using random sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5132, Accuracy: 0.8343
Selected 68 samples using random sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5090, Accuracy: 0.8307
Selected 68 samples using random sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5050, Accuracy: 0.8273
Selected 68 samples using random sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5088, Accuracy: 0.8311
Selected 68 samples using random sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5096, Accuracy: 0.8311

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.5085, Accuracy: 0.8277
Run 8 completed - Active F1: 0.5145, Passive F1: 0.5085

--- Run 9/10 ---

============================================================
ACTIVE LEARNING EXPERIMENT
============================================================
  Using diversity sampling for initial pool...
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3425, Accuracy: 0.7176
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4128, Accuracy: 0.8832
Selected 68 samples using uncertainty sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4533, Accuracy: 0.8933
Selected 68 samples using diversity sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4649, Accuracy: 0.8937
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4934, Accuracy: 0.8936
Selected 68 samples using diversity sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4829, Accuracy: 0.8913
Selected 68 samples using uncertainty sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4958, Accuracy: 0.8926
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5154, Accuracy: 0.8958
Selected 68 samples using diversity sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5085, Accuracy: 0.8958
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5045, Accuracy: 0.8925
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5043, Accuracy: 0.8878

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4956, Accuracy: 0.8852

============================================================
PASSIVE LEARNING EXPERIMENT
============================================================
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4865, Accuracy: 0.8401
Selected 68 samples using random sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4504, Accuracy: 0.8114
Selected 68 samples using random sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4561, Accuracy: 0.8134
Selected 68 samples using random sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4959, Accuracy: 0.8308
Selected 68 samples using random sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4879, Accuracy: 0.8239
Selected 68 samples using random sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4945, Accuracy: 0.8273
Selected 68 samples using random sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4869, Accuracy: 0.8217
Selected 68 samples using random sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4778, Accuracy: 0.8166
Selected 68 samples using random sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4793, Accuracy: 0.8141
Selected 68 samples using random sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4891, Accuracy: 0.8181
Selected 68 samples using random sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4856, Accuracy: 0.8173

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4848, Accuracy: 0.8146
Run 9 completed - Active F1: 0.4956, Passive F1: 0.4848

--- Run 10/10 ---

============================================================
ACTIVE LEARNING EXPERIMENT
============================================================
  Using diversity sampling for initial pool...
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.2725, Accuracy: 0.8782
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3143, Accuracy: 0.8872
Selected 68 samples using uncertainty sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3906, Accuracy: 0.8922
Selected 68 samples using diversity sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4143, Accuracy: 0.8937
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4477, Accuracy: 0.8956
Selected 68 samples using diversity sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4614, Accuracy: 0.8958
Selected 68 samples using uncertainty sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4627, Accuracy: 0.8934
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4721, Accuracy: 0.8955
Selected 68 samples using diversity sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4821, Accuracy: 0.8958
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4950, Accuracy: 0.8962
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5016, Accuracy: 0.8942

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4865, Accuracy: 0.8924

============================================================
PASSIVE LEARNING EXPERIMENT
============================================================
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4451, Accuracy: 0.8184
Selected 68 samples using random sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4444, Accuracy: 0.8185
Selected 68 samples using random sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4425, Accuracy: 0.8105
Selected 68 samples using random sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4525, Accuracy: 0.8137
Selected 68 samples using random sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4675, Accuracy: 0.8224
Selected 68 samples using random sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4714, Accuracy: 0.8249
Selected 68 samples using random sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4819, Accuracy: 0.8300
Selected 68 samples using random sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4690, Accuracy: 0.8190
Selected 68 samples using random sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4782, Accuracy: 0.8232
Selected 68 samples using random sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4815, Accuracy: 0.8255
Selected 68 samples using random sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4829, Accuracy: 0.8242

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4941, Accuracy: 0.8282
Run 10 completed - Active F1: 0.4865, Passive F1: 0.4941

================================================================================
STATISTICAL SIGNIFICANCE TESTING
================================================================================
Active Learning F1: 0.4900 Â± 0.0126
Passive Learning F1: 0.5013 Â± 0.0108
Difference: -0.0113

Paired t-test:
  t-statistic: -2.2001
  p-value: 0.055334
  Significant (Î±=0.05): No

Wilcoxon signed-rank test:
  W-statistic: 9.0000
  p-value: 0.064453
  Significant (Î±=0.05): No

Effect size (Cohen's d): -0.9663
Effect size interpretation: large

95% Confidence Intervals:
  Active Learning: [0.4809, 0.4990]
  Passive Learning: [0.4936, 0.5090]

Statistical results saved to: statistical_results_config123.csv

ğŸ” DEBUG: Data Sources for Tables
Statistical Test Data Table: All 10 runs (Final Test Set Performance)
Iteration Progression Plot: Run 1 (Validation Set Performance)
Summary Section: Run 1 (Final Test Set Performance)
Note: Statistical test data shows all runs, iteration plot shows training progress

================================================================================
STATISTICAL TEST DATA COMPARISON (Final Test Set Performance)
================================================================================
Note: This table shows the final test set F1 scores used in statistical significance testing
Each row represents one complete experiment run with different random seeds

 Run  Random_Seed  Active_F1  Passive_F1  Active_Accuracy  Passive_Accuracy  F1_Improvement  Improvement_%
   1           42   0.477362    0.494024         0.896605          0.817428       -0.016662      -3.372762
   2           43   0.487100    0.508645         0.890081          0.827159       -0.021545      -4.235758
   3           44   0.478236    0.518253         0.897932          0.836559       -0.040017      -7.721450
   4           45   0.492627    0.487663         0.897269          0.804821        0.004964       1.017854
   5           46   0.490937    0.500152         0.891297          0.818755       -0.009215      -1.842468
   6           47   0.470655    0.500960         0.896273          0.827491       -0.030305      -6.049402
   7           48   0.505974    0.515840         0.894836          0.832688       -0.009866      -1.912604
   8           49   0.514493    0.508517         0.896273          0.827712        0.005975       1.175064
   9           50   0.495627    0.484793         0.885215          0.814553        0.010834       2.234810
  10           51   0.486544    0.494141         0.892403          0.828154       -0.007597      -1.537435

================================================================================
SUMMARY STATISTICS (All 10 Runs)
================================================================================
Active Learning F1: 0.4900 Â± 0.0126
Passive Learning F1: 0.5013 Â± 0.0108
Mean Improvement: -0.0113
Mean Improvement %: -2.26%

Statistical test data saved to: /Users/lucasbraga/Documents/GitHub/active-learning/active-learning/experimentation/data/statistical_test_data_config123.csv
Iteration progression plot saved to: /Users/lucasbraga/Documents/GitHub/active-learning/active-learning/experimentation/data/active_vs_passive_comparison_config123.png

ğŸ“ Logging completed - Check the logs folder for detailed output
