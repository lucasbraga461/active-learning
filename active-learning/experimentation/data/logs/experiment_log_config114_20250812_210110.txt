ğŸ“ Logging started - Output will be saved to: /Users/lucasbraga/Documents/GitHub/active-learning/active-learning/experimentation/data/logs/experiment_log_config114_20250812_210110.txt
â° Timestamp: 2025-08-12 21:01:10
================================================================================
ğŸ¦ Bank Marketing Dataset - Active Learning vs Passive Learning Comparison
================================================================================
Dataset: UCI Bank Marketing (Portuguese Bank)
Target: Whether customer subscribed to term deposit (yes/no)
Features: Age, job, marital status, education, balance, housing, loan, etc.
================================================================================
ğŸš€ ENHANCEMENT: Using Logistic Regression WITHOUT Regularization
ğŸ¯ GOAL: Test if lack of regularization was the limiting factor
ğŸ”§ Model: LogisticRegression() with DEFAULT parameters
================================================================================
ğŸ“Š Dataset Size: 45,211 rows (Full dataset)
ğŸ“Š Expected splits: ~36,169 train, ~9,042 test
================================================================================
Model Configuration:
  Model Type: Logistic Regression (NO regularization)
  Parameters: DEFAULT (C=1.0, penalty='l2', but C=1.0 means no penalty)

Plot Configuration:
  Show Plots: False

Experiment Configuration:
  Initial samples: 300
  Initial strategy: diversity
  Batch size: 68
  Iterations: 11
  Strategies: ['uncertainty', 'diversity', 'uncertainty', 'uncertainty', 'diversity', 'uncertainty', 'uncertainty', 'diversity', 'uncertainty', 'uncertainty', 'qbc']
  âœ“ Initial strategy 'diversity' is valid

ğŸ“Š Using FULL bank dataset (45,211 rows)
âœ… Loading bank dataset from: /Users/lucasbraga/Documents/GitHub/active-learning/active-learning/data/uci_dataset_00222_bank/bank-full.csv
Feature type: Numerical age and balance
Loading and splitting data...
Dataset shape: (45211, 17)
Cleaning and preprocessing bank dataset...
ğŸ§¹ Cleaning and preprocessing bank dataset...
  ğŸ“Š Original dataset shape: (45211, 17)
  ğŸ” Missing values in original data:
    No missing values found
  âœ“ Using numerical age features (normalized + squared)
  âœ“ Using numerical balance features (log-transformed + normalized)
  ğŸ” Checking for NaN values after preprocessing...
    Found NaN values in columns:
balance_norm    1
dtype: int64
    ğŸ§¹ Filling NaN values...
      balance_norm: filled with median (-0.3586)
  ğŸ”§ Applying global feature standardization...
    ğŸ”’ Using sorted column order for reproducibility: ['age_norm', 'age_squared', 'balance_norm', 'campaign', 'default_bool', 'duration', 'housing_bool', 'loan_bool', 'month_cos', 'month_sin']
    âœ“ Standardized 10 numerical features
    ğŸ”’ Standardization parameters:
      Mean values: {'age_norm': 2.0116668549090447e-16, 'age_squared': 0.9999778814890183, 'balance_norm': -7.93146638145373e-06, 'campaign': 2.763840658246887, 'default_bool': 0.018026586450200173, 'duration': 258.1630797814691, 'housing_bool': 0.5558381809736569, 'loan_bool': 0.16022649355245405, 'month_cos': -0.4703013950820929, 'month_sin': 0.01844905737733411}
      Scale values: {'age_norm': 0.999988940683355, 'age_squared': 1.5229247271132622, 'balance_norm': 0.9999793033137726, 'campaign': 3.097986621285248, 'default_bool': 0.133047467586398, 'duration': 257.5249641835511, 'housing_bool': 0.4968723151329254, 'loan_bool': 0.3668159815443426, 'month_cos': 0.6348584209990016, 'month_sin': 0.6127242571927273}
  ğŸ“Š Final dataset shape: (45211, 31)
  ğŸ¯ Target distribution: {0: 39922, 1: 5289}
Features after preprocessing: 31
Label distribution: {0: 39922, 1: 5289}
Train set: 36168 samples
Test set: 9043 samples
Label distribution in train: {0: 31937, 1: 4231}

================================================================================
RUNNING 10 EXPERIMENTS FOR STATISTICAL SIGNIFICANCE
================================================================================

--- Run 1/10 ---

============================================================
ACTIVE LEARNING EXPERIMENT
============================================================
  Using diversity sampling for initial pool...
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3562, Accuracy: 0.8716
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3481, Accuracy: 0.8944
Selected 68 samples using diversity sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3762, Accuracy: 0.8955
Selected 68 samples using uncertainty sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4313, Accuracy: 0.8987
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4444, Accuracy: 0.8970
Selected 68 samples using diversity sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4563, Accuracy: 0.8969
Selected 68 samples using uncertainty sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4590, Accuracy: 0.8987
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4725, Accuracy: 0.8994
Selected 68 samples using diversity sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4720, Accuracy: 0.8995
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4786, Accuracy: 0.9006
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4847, Accuracy: 0.9001

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4626, Accuracy: 0.8975

============================================================
PASSIVE LEARNING EXPERIMENT
============================================================
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4647, Accuracy: 0.8124
Selected 68 samples using random sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4837, Accuracy: 0.8200
Selected 68 samples using random sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4776, Accuracy: 0.8197
Selected 68 samples using random sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4838, Accuracy: 0.8265
Selected 68 samples using random sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4757, Accuracy: 0.8199
Selected 68 samples using random sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4634, Accuracy: 0.8095
Selected 68 samples using random sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4720, Accuracy: 0.8083
Selected 68 samples using random sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4794, Accuracy: 0.8114
Selected 68 samples using random sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4792, Accuracy: 0.8101
Selected 68 samples using random sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4841, Accuracy: 0.8159
Selected 68 samples using random sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4902, Accuracy: 0.8166

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4940, Accuracy: 0.8174
Run 1 completed - Active F1: 0.4626, Passive F1: 0.4940

--- Run 2/10 ---

============================================================
ACTIVE LEARNING EXPERIMENT
============================================================
  Using diversity sampling for initial pool...
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3907, Accuracy: 0.8659
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4045, Accuracy: 0.8824
Selected 68 samples using diversity sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4185, Accuracy: 0.8855
Selected 68 samples using uncertainty sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4423, Accuracy: 0.8965
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4513, Accuracy: 0.8911
Selected 68 samples using diversity sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4536, Accuracy: 0.8901
Selected 68 samples using uncertainty sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4539, Accuracy: 0.8919
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4451, Accuracy: 0.8904
Selected 68 samples using diversity sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4594, Accuracy: 0.8913
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4582, Accuracy: 0.8898
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4718, Accuracy: 0.8898

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4890, Accuracy: 0.8951

============================================================
PASSIVE LEARNING EXPERIMENT
============================================================
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4826, Accuracy: 0.8236
Selected 68 samples using random sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4797, Accuracy: 0.8207
Selected 68 samples using random sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4780, Accuracy: 0.8213
Selected 68 samples using random sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4801, Accuracy: 0.8228
Selected 68 samples using random sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4904, Accuracy: 0.8204
Selected 68 samples using random sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5060, Accuracy: 0.8280
Selected 68 samples using random sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5041, Accuracy: 0.8249
Selected 68 samples using random sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5035, Accuracy: 0.8239
Selected 68 samples using random sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5092, Accuracy: 0.8262
Selected 68 samples using random sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5140, Accuracy: 0.8296
Selected 68 samples using random sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5157, Accuracy: 0.8297

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.5086, Accuracy: 0.8272
Run 2 completed - Active F1: 0.4890, Passive F1: 0.5086

--- Run 3/10 ---

============================================================
ACTIVE LEARNING EXPERIMENT
============================================================
  Using diversity sampling for initial pool...
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3516, Accuracy: 0.8542
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3698, Accuracy: 0.8916
Selected 68 samples using diversity sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3833, Accuracy: 0.8915
Selected 68 samples using uncertainty sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3893, Accuracy: 0.8929
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4174, Accuracy: 0.8942
Selected 68 samples using diversity sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4297, Accuracy: 0.8940
Selected 68 samples using uncertainty sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4500, Accuracy: 0.8959
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4526, Accuracy: 0.8947
Selected 68 samples using diversity sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4582, Accuracy: 0.8951
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4816, Accuracy: 0.8967
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4762, Accuracy: 0.8966

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4897, Accuracy: 0.8988

============================================================
PASSIVE LEARNING EXPERIMENT
============================================================
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4889, Accuracy: 0.8283
Selected 68 samples using random sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4908, Accuracy: 0.8239
Selected 68 samples using random sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5103, Accuracy: 0.8355
Selected 68 samples using random sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5091, Accuracy: 0.8358
Selected 68 samples using random sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5124, Accuracy: 0.8392
Selected 68 samples using random sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5190, Accuracy: 0.8358
Selected 68 samples using random sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5180, Accuracy: 0.8372
Selected 68 samples using random sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5192, Accuracy: 0.8372
Selected 68 samples using random sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5145, Accuracy: 0.8356
Selected 68 samples using random sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5201, Accuracy: 0.8385
Selected 68 samples using random sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5198, Accuracy: 0.8361

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.5183, Accuracy: 0.8366
Run 3 completed - Active F1: 0.4897, Passive F1: 0.5183

--- Run 4/10 ---

============================================================
ACTIVE LEARNING EXPERIMENT
============================================================
  Using diversity sampling for initial pool...
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3436, Accuracy: 0.7813
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4077, Accuracy: 0.8763
Selected 68 samples using diversity sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4256, Accuracy: 0.8772
Selected 68 samples using uncertainty sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4245, Accuracy: 0.8894
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4444, Accuracy: 0.8887
Selected 68 samples using diversity sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4434, Accuracy: 0.8879
Selected 68 samples using uncertainty sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4492, Accuracy: 0.8891
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4646, Accuracy: 0.8904
Selected 68 samples using diversity sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4623, Accuracy: 0.8878
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4788, Accuracy: 0.8880
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4955, Accuracy: 0.8908

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.5029, Accuracy: 0.8951

============================================================
PASSIVE LEARNING EXPERIMENT
============================================================
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4226, Accuracy: 0.7870
Selected 68 samples using random sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4347, Accuracy: 0.7835
Selected 68 samples using random sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4545, Accuracy: 0.7976
Selected 68 samples using random sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4544, Accuracy: 0.7939
Selected 68 samples using random sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4507, Accuracy: 0.7860
Selected 68 samples using random sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4608, Accuracy: 0.7920
Selected 68 samples using random sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4596, Accuracy: 0.7900
Selected 68 samples using random sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4610, Accuracy: 0.7906
Selected 68 samples using random sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4711, Accuracy: 0.7949
Selected 68 samples using random sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4715, Accuracy: 0.7973
Selected 68 samples using random sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4739, Accuracy: 0.7996

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4877, Accuracy: 0.8048
Run 4 completed - Active F1: 0.5029, Passive F1: 0.4877

--- Run 5/10 ---

============================================================
ACTIVE LEARNING EXPERIMENT
============================================================
  Using diversity sampling for initial pool...
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3643, Accuracy: 0.7737
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4303, Accuracy: 0.8712
Selected 68 samples using diversity sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4538, Accuracy: 0.8782
Selected 68 samples using uncertainty sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4591, Accuracy: 0.8831
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4661, Accuracy: 0.8825
Selected 68 samples using diversity sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4786, Accuracy: 0.8853
Selected 68 samples using uncertainty sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4906, Accuracy: 0.8872
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4994, Accuracy: 0.8883
Selected 68 samples using diversity sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5019, Accuracy: 0.8886
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4906, Accuracy: 0.8835
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4928, Accuracy: 0.8879

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.5055, Accuracy: 0.8910

============================================================
PASSIVE LEARNING EXPERIMENT
============================================================
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4709, Accuracy: 0.8077
Selected 68 samples using random sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4960, Accuracy: 0.8174
Selected 68 samples using random sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5027, Accuracy: 0.8236
Selected 68 samples using random sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5085, Accuracy: 0.8282
Selected 68 samples using random sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5073, Accuracy: 0.8268
Selected 68 samples using random sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5095, Accuracy: 0.8249
Selected 68 samples using random sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5048, Accuracy: 0.8221
Selected 68 samples using random sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4902, Accuracy: 0.8091
Selected 68 samples using random sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4992, Accuracy: 0.8164
Selected 68 samples using random sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4983, Accuracy: 0.8168
Selected 68 samples using random sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4998, Accuracy: 0.8193

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.5002, Accuracy: 0.8188
Run 5 completed - Active F1: 0.5055, Passive F1: 0.5002

--- Run 6/10 ---

============================================================
ACTIVE LEARNING EXPERIMENT
============================================================
  Using diversity sampling for initial pool...
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3496, Accuracy: 0.8786
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3528, Accuracy: 0.8915
Selected 68 samples using diversity sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3911, Accuracy: 0.8941
Selected 68 samples using uncertainty sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4060, Accuracy: 0.8965
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4217, Accuracy: 0.8969
Selected 68 samples using diversity sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4407, Accuracy: 0.8983
Selected 68 samples using uncertainty sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4484, Accuracy: 0.8966
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4372, Accuracy: 0.8954
Selected 68 samples using diversity sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4514, Accuracy: 0.8955
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4536, Accuracy: 0.8951
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4746, Accuracy: 0.8969

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4821, Accuracy: 0.8993

============================================================
PASSIVE LEARNING EXPERIMENT
============================================================
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4972, Accuracy: 0.8502
Selected 68 samples using random sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4988, Accuracy: 0.8528
Selected 68 samples using random sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5002, Accuracy: 0.8464
Selected 68 samples using random sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4998, Accuracy: 0.8401
Selected 68 samples using random sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4965, Accuracy: 0.8326
Selected 68 samples using random sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5082, Accuracy: 0.8392
Selected 68 samples using random sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5042, Accuracy: 0.8349
Selected 68 samples using random sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5140, Accuracy: 0.8374
Selected 68 samples using random sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5050, Accuracy: 0.8296
Selected 68 samples using random sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5059, Accuracy: 0.8261
Selected 68 samples using random sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5045, Accuracy: 0.8268

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.5010, Accuracy: 0.8275
Run 6 completed - Active F1: 0.4821, Passive F1: 0.5010

--- Run 7/10 ---

============================================================
ACTIVE LEARNING EXPERIMENT
============================================================
  Using diversity sampling for initial pool...
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4337, Accuracy: 0.8737
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4455, Accuracy: 0.8826
Selected 68 samples using diversity sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4324, Accuracy: 0.8817
Selected 68 samples using uncertainty sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4744, Accuracy: 0.8848
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4748, Accuracy: 0.8918
Selected 68 samples using diversity sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4901, Accuracy: 0.8927
Selected 68 samples using uncertainty sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5032, Accuracy: 0.8916
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5114, Accuracy: 0.8936
Selected 68 samples using diversity sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5119, Accuracy: 0.8927
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5111, Accuracy: 0.8905
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5074, Accuracy: 0.8897

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.5205, Accuracy: 0.8955

============================================================
PASSIVE LEARNING EXPERIMENT
============================================================
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5316, Accuracy: 0.8533
Selected 68 samples using random sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5094, Accuracy: 0.8333
Selected 68 samples using random sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5143, Accuracy: 0.8378
Selected 68 samples using random sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5130, Accuracy: 0.8338
Selected 68 samples using random sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5165, Accuracy: 0.8320
Selected 68 samples using random sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5084, Accuracy: 0.8305
Selected 68 samples using random sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5067, Accuracy: 0.8264
Selected 68 samples using random sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5117, Accuracy: 0.8298
Selected 68 samples using random sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5076, Accuracy: 0.8254
Selected 68 samples using random sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5105, Accuracy: 0.8287
Selected 68 samples using random sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5125, Accuracy: 0.8304

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.5158, Accuracy: 0.8327
Run 7 completed - Active F1: 0.5205, Passive F1: 0.5158

--- Run 8/10 ---

============================================================
ACTIVE LEARNING EXPERIMENT
============================================================
  Using diversity sampling for initial pool...
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3710, Accuracy: 0.7985
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4275, Accuracy: 0.8815
Selected 68 samples using diversity sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4150, Accuracy: 0.8811
Selected 68 samples using uncertainty sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4583, Accuracy: 0.8941
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4782, Accuracy: 0.8926
Selected 68 samples using diversity sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4677, Accuracy: 0.8918
Selected 68 samples using uncertainty sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4772, Accuracy: 0.8907
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4939, Accuracy: 0.8904
Selected 68 samples using diversity sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4975, Accuracy: 0.8900
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5205, Accuracy: 0.8933
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5257, Accuracy: 0.8942

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.5285, Accuracy: 0.8946

============================================================
PASSIVE LEARNING EXPERIMENT
============================================================
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4741, Accuracy: 0.8163
Selected 68 samples using random sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4862, Accuracy: 0.8221
Selected 68 samples using random sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4876, Accuracy: 0.8146
Selected 68 samples using random sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5054, Accuracy: 0.8222
Selected 68 samples using random sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5063, Accuracy: 0.8280
Selected 68 samples using random sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5076, Accuracy: 0.8257
Selected 68 samples using random sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5132, Accuracy: 0.8343
Selected 68 samples using random sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5090, Accuracy: 0.8307
Selected 68 samples using random sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5050, Accuracy: 0.8273
Selected 68 samples using random sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5088, Accuracy: 0.8311
Selected 68 samples using random sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5096, Accuracy: 0.8311

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.5085, Accuracy: 0.8277
Run 8 completed - Active F1: 0.5285, Passive F1: 0.5085

--- Run 9/10 ---

============================================================
ACTIVE LEARNING EXPERIMENT
============================================================
  Using diversity sampling for initial pool...
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3425, Accuracy: 0.7176
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4128, Accuracy: 0.8832
Selected 68 samples using diversity sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4356, Accuracy: 0.8861
Selected 68 samples using uncertainty sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4545, Accuracy: 0.8889
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4672, Accuracy: 0.8922
Selected 68 samples using diversity sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4672, Accuracy: 0.8922
Selected 68 samples using uncertainty sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4708, Accuracy: 0.8937
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4856, Accuracy: 0.8963
Selected 68 samples using diversity sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4729, Accuracy: 0.8925
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4902, Accuracy: 0.8962
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4895, Accuracy: 0.8925

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4925, Accuracy: 0.8917

============================================================
PASSIVE LEARNING EXPERIMENT
============================================================
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4865, Accuracy: 0.8401
Selected 68 samples using random sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4504, Accuracy: 0.8114
Selected 68 samples using random sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4561, Accuracy: 0.8134
Selected 68 samples using random sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4959, Accuracy: 0.8308
Selected 68 samples using random sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4879, Accuracy: 0.8239
Selected 68 samples using random sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4945, Accuracy: 0.8273
Selected 68 samples using random sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4869, Accuracy: 0.8217
Selected 68 samples using random sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4778, Accuracy: 0.8166
Selected 68 samples using random sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4793, Accuracy: 0.8141
Selected 68 samples using random sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4891, Accuracy: 0.8181
Selected 68 samples using random sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4856, Accuracy: 0.8173

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4848, Accuracy: 0.8146
Run 9 completed - Active F1: 0.4925, Passive F1: 0.4848

--- Run 10/10 ---

============================================================
ACTIVE LEARNING EXPERIMENT
============================================================
  Using diversity sampling for initial pool...
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.2725, Accuracy: 0.8782
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3143, Accuracy: 0.8872
Selected 68 samples using diversity sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.3581, Accuracy: 0.8900
Selected 68 samples using uncertainty sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4090, Accuracy: 0.8941
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4480, Accuracy: 0.8937
Selected 68 samples using diversity sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4566, Accuracy: 0.8944
Selected 68 samples using uncertainty sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4631, Accuracy: 0.8965
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4871, Accuracy: 0.8952
Selected 68 samples using diversity sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4921, Accuracy: 0.8936
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5046, Accuracy: 0.8949
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.5155, Accuracy: 0.8942

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.5040, Accuracy: 0.8910

============================================================
PASSIVE LEARNING EXPERIMENT
============================================================
Initial labeled pool: 300 samples
Remaining unlabeled: 28634 samples

--- Iteration 1 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4451, Accuracy: 0.8184
Selected 68 samples using random sampling
Total labeled samples: 368
Remaining unlabeled: 28566

--- Iteration 2 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4444, Accuracy: 0.8185
Selected 68 samples using random sampling
Total labeled samples: 436
Remaining unlabeled: 28498

--- Iteration 3 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4425, Accuracy: 0.8105
Selected 68 samples using random sampling
Total labeled samples: 504
Remaining unlabeled: 28430

--- Iteration 4 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4525, Accuracy: 0.8137
Selected 68 samples using random sampling
Total labeled samples: 572
Remaining unlabeled: 28362

--- Iteration 5 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4675, Accuracy: 0.8224
Selected 68 samples using random sampling
Total labeled samples: 640
Remaining unlabeled: 28294

--- Iteration 6 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4714, Accuracy: 0.8249
Selected 68 samples using random sampling
Total labeled samples: 708
Remaining unlabeled: 28226

--- Iteration 7 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4819, Accuracy: 0.8300
Selected 68 samples using random sampling
Total labeled samples: 776
Remaining unlabeled: 28158

--- Iteration 8 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4690, Accuracy: 0.8190
Selected 68 samples using random sampling
Total labeled samples: 844
Remaining unlabeled: 28090

--- Iteration 9 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4782, Accuracy: 0.8232
Selected 68 samples using random sampling
Total labeled samples: 912
Remaining unlabeled: 28022

--- Iteration 10 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4815, Accuracy: 0.8255
Selected 68 samples using random sampling
Total labeled samples: 980
Remaining unlabeled: 27954

--- Iteration 11 ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Validation - F1: 0.4829, Accuracy: 0.8242

--- Final Test Evaluation ---
  ğŸ“Š Using Logistic Regression with DEFAULT parameters (no regularization)
Test Performance - F1: 0.4941, Accuracy: 0.8282
Run 10 completed - Active F1: 0.5040, Passive F1: 0.4941

================================================================================
STATISTICAL SIGNIFICANCE TESTING
================================================================================
Active Learning F1: 0.4977 Â± 0.0180
Passive Learning F1: 0.5013 Â± 0.0108
Difference: -0.0036

Paired t-test:
  t-statistic: -0.5942
  p-value: 0.566988
  Significant (Î±=0.05): No

Wilcoxon signed-rank test:
  W-statistic: 23.0000
  p-value: 0.695312
  Significant (Î±=0.05): No

Effect size (Cohen's d): -0.2408
Effect size interpretation: small

95% Confidence Intervals:
  Active Learning: [0.4849, 0.5106]
  Passive Learning: [0.4936, 0.5090]

Statistical results saved to: statistical_results_config114.csv

ğŸ” DEBUG: Data Sources for Tables
Statistical Test Data Table: All 10 runs (Final Test Set Performance)
Iteration Progression Plot: Run 1 (Validation Set Performance)
Summary Section: Run 1 (Final Test Set Performance)
Note: Statistical test data shows all runs, iteration plot shows training progress

================================================================================
STATISTICAL TEST DATA COMPARISON (Final Test Set Performance)
================================================================================
Note: This table shows the final test set F1 scores used in statistical significance testing
Each row represents one complete experiment run with different random seeds

 Run  Random_Seed  Active_F1  Passive_F1  Active_Accuracy  Passive_Accuracy  F1_Improvement  Improvement_%
   1           42   0.462609    0.494024         0.897490          0.817428       -0.031415      -6.359046
   2           43   0.488961    0.508645         0.895057          0.827159       -0.019684      -3.869966
   3           44   0.489682    0.518253         0.898817          0.836559       -0.028571      -5.512914
   4           45   0.502881    0.487663         0.895057          0.804821        0.015218       3.120557
   5           46   0.505517    0.500152         0.890965          0.818755        0.005364       1.072486
   6           47   0.482092    0.500960         0.899259          0.827491       -0.018868      -3.766290
   7           48   0.520548    0.515840         0.895499          0.832688        0.004708       0.912675
   8           49   0.528451    0.508517         0.894615          0.827712        0.019934       3.920006
   9           50   0.492483    0.484793         0.891739          0.814553        0.007691       1.586354
  10           51   0.504024    0.494141         0.890965          0.828154        0.009884       2.000143

================================================================================
SUMMARY STATISTICS (All 10 Runs)
================================================================================
Active Learning F1: 0.4977 Â± 0.0180
Passive Learning F1: 0.5013 Â± 0.0108
Mean Improvement: -0.0036
Mean Improvement %: -0.71%

Statistical test data saved to: /Users/lucasbraga/Documents/GitHub/active-learning/active-learning/experimentation/data/statistical_test_data_config114.csv
Iteration progression plot saved to: /Users/lucasbraga/Documents/GitHub/active-learning/active-learning/experimentation/data/active_vs_passive_comparison_config114.png

ğŸ“ Logging completed - Check the logs folder for detailed output
