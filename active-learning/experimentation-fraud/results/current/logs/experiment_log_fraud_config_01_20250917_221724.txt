📝 Logging started - Output will be saved to: /Users/lucasbraga/Documents/GitHub/active-learning/experimentation-fraud/data/logs/experiment_log_fraud_config_01_20250917_221724.txt
⏰ Timestamp: 2025-09-17 22:17:24
================================================================================
💳 Credit Card Fraud Detection - Active Learning vs Passive Learning Comparison
================================================================================
Dataset: Kaggle European Credit Card Fraud Dataset
Target: Fraud detection (Class: 0=non-fraud, 1=fraud)
Features: Time, V1-V28 (anonymized), Amount
================================================================================
🎯 Implementation: Stratified passive learning maintains fraud representation
================================================================================
Model Configuration:
  Model Type: logistic

Plot Configuration:
  Show Plots: False

Experiment Configuration:
  Initial samples: 300
  Initial strategy: stratified
  Batch size: 68
  Iterations: 11
  Strategies: ['uncertainty', 'uncertainty', 'uncertainty', 'uncertainty', 'diversity', 'diversity', 'uncertainty', 'diversity', 'uncertainty', 'uncertainty', 'qbc']

✅ Loading fraud dataset from: /Users/lucasbraga/Documents/GitHub/active-learning/active-learning/data/european-credit-card-dataset/creditcard.csv
Loading and splitting credit card fraud data...
Dataset shape: (284807, 31)
🧹 Cleaning and preprocessing credit card fraud dataset...
  📊 Original dataset shape: (284807, 31)
  🔍 Missing values in original data:
    No missing values found
  🎯 Target distribution: {0: 284315, 1: 492}
  ⚠️  Fraud percentage: 0.173%
  ✓ Added cyclical time features (hour of day)
  ✓ Added log-transformed amount feature
  ✓ Added amount bins for interpretability
  ✓ One-hot encoded categorical features
  🔍 Checking for NaN values after preprocessing...
    ✓ No NaN values found after preprocessing
  🔧 Applying feature standardization...
    🔒 Using sorted column order for reproducibility
    ✓ Standardized 31 numerical features
    ✓ Kept 6 categorical features unchanged (already 0/1)
  📊 Final dataset shape: (284807, 37)
  🎯 Final target distribution: {0: 284315, 1: 492}
  📋 Feature columns: ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Time_hour_sin', 'Time_hour_cos', 'Amount_log', 'Amount_very_small', 'Amount_small', 'Amount_medium', 'Amount_large', 'Amount_very_large', 'Amount_extreme']
Features after preprocessing: 37
Label distribution: {0: 284315, 1: 492}
Train set: 227845 samples
Test set: 56962 samples
Label distribution in train: {0: 227451, 1: 394}
Label distribution in test: {0: 56864, 1: 98}

🧪 RUNNING STRATIFIED PASSIVE LEARNING EXPERIMENT

============================================================
ACTIVE LEARNING EXPERIMENT - FRAUD DETECTION
============================================================
  🎯 Creating stratified initial split with 300 samples...
    Available fraud samples: 315
    Available non-fraud samples: 181961
    ✓ Selected 10 fraud + 290 non-fraud samples
    ✓ Initial fraud percentage: 3.33%
Initial labeled pool: 300 samples
Initial fraud in labeled: 10 samples (3.33%)
Remaining unlabeled: 181976 samples

--- Iteration 1 ---
Validation - F1: 0.6936, Accuracy: 0.9988, Precision: 0.6383, Recall: 0.7595
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Fraud in labeled: 10 samples (2.72%)
Remaining unlabeled: 181908

--- Iteration 2 ---
Validation - F1: 0.7947, Accuracy: 0.9993, Precision: 0.8333, Recall: 0.7595
Selected 68 samples using uncertainty sampling
Total labeled samples: 436
Fraud in labeled: 10 samples (2.29%)
Remaining unlabeled: 181840

--- Iteration 3 ---
Validation - F1: 0.7947, Accuracy: 0.9993, Precision: 0.8333, Recall: 0.7595
Selected 68 samples using uncertainty sampling
Total labeled samples: 504
Fraud in labeled: 11 samples (2.18%)
Remaining unlabeled: 181772

--- Iteration 4 ---
Validation - F1: 0.2367, Accuracy: 0.9905, Precision: 0.1376, Recall: 0.8481
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Fraud in labeled: 11 samples (1.92%)
Remaining unlabeled: 181704

--- Iteration 5 ---
Validation - F1: 0.6220, Accuracy: 0.9983, Precision: 0.5000, Recall: 0.8228
Selected 68 samples using diversity sampling
Total labeled samples: 640
Fraud in labeled: 20 samples (3.12%)
Remaining unlabeled: 181636

--- Iteration 6 ---
Validation - F1: 0.7711, Accuracy: 0.9992, Precision: 0.7356, Recall: 0.8101
Selected 68 samples using diversity sampling
Total labeled samples: 708
Fraud in labeled: 26 samples (3.67%)
Remaining unlabeled: 181568

--- Iteration 7 ---
Validation - F1: 0.7901, Accuracy: 0.9993, Precision: 0.7711, Recall: 0.8101
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Fraud in labeled: 34 samples (4.38%)
Remaining unlabeled: 181500

--- Iteration 8 ---
Validation - F1: 0.3785, Accuracy: 0.9952, Precision: 0.2436, Recall: 0.8481
Selected 68 samples using diversity sampling
Total labeled samples: 844
Fraud in labeled: 41 samples (4.86%)
Remaining unlabeled: 181432

--- Iteration 9 ---
Validation - F1: 0.4012, Accuracy: 0.9956, Precision: 0.2627, Recall: 0.8481
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Fraud in labeled: 41 samples (4.50%)
Remaining unlabeled: 181364

--- Iteration 10 ---
Validation - F1: 0.5197, Accuracy: 0.9973, Precision: 0.3771, Recall: 0.8354
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Fraud in labeled: 42 samples (4.29%)
Remaining unlabeled: 181296

--- Iteration 11 ---
Validation - F1: 0.6377, Accuracy: 0.9984, Precision: 0.5156, Recall: 0.8354

--- Final Test Evaluation ---
Test Performance - F1: 0.6007, Accuracy: 0.9980, Precision: 0.4595, Recall: 0.8673

============================================================
PASSIVE LEARNING EXPERIMENT - FRAUD DETECTION
============================================================
  🎯 Creating stratified initial split with 300 samples...
    Available fraud samples: 315
    Available non-fraud samples: 181961
    ✓ Selected 10 fraud + 290 non-fraud samples
    ✓ Initial fraud percentage: 3.33%
Initial labeled pool: 300 samples
Initial fraud in labeled: 10 samples (3.33%)
Remaining unlabeled: 181976 samples
🎯 Using stratified passive sampling

--- Iteration 1 ---
Validation - F1: 0.6936, Accuracy: 0.9988, Precision: 0.6383, Recall: 0.7595
  🎯 Using STRATIFIED random sampling (maintaining 10.0% fraud ratio)
    ✓ Selected 6 fraud + 62 non-fraud
    ✓ Actual fraud ratio: 8.82%
Total labeled samples: 368
Fraud in labeled: 16 samples (4.35%)
Remaining unlabeled: 181908

--- Iteration 2 ---
Validation - F1: 0.1570, Accuracy: 0.9856, Precision: 0.0874, Recall: 0.7722
  🎯 Using STRATIFIED random sampling (maintaining 10.0% fraud ratio)
    ✓ Selected 6 fraud + 62 non-fraud
    ✓ Actual fraud ratio: 8.82%
Total labeled samples: 436
Fraud in labeled: 22 samples (5.05%)
Remaining unlabeled: 181840

--- Iteration 3 ---
Validation - F1: 0.1387, Accuracy: 0.9823, Precision: 0.0758, Recall: 0.8228
  🎯 Using STRATIFIED random sampling (maintaining 10.0% fraud ratio)
    ✓ Selected 6 fraud + 62 non-fraud
    ✓ Actual fraud ratio: 8.82%
Total labeled samples: 504
Fraud in labeled: 28 samples (5.56%)
Remaining unlabeled: 181772

--- Iteration 4 ---
Validation - F1: 0.0792, Accuracy: 0.9648, Precision: 0.0415, Recall: 0.8734
  🎯 Using STRATIFIED random sampling (maintaining 10.0% fraud ratio)
    ✓ Selected 6 fraud + 62 non-fraud
    ✓ Actual fraud ratio: 8.82%
Total labeled samples: 572
Fraud in labeled: 34 samples (5.94%)
Remaining unlabeled: 181704

--- Iteration 5 ---
Validation - F1: 0.0821, Accuracy: 0.9671, Precision: 0.0431, Recall: 0.8481
  🎯 Using STRATIFIED random sampling (maintaining 10.0% fraud ratio)
    ✓ Selected 6 fraud + 62 non-fraud
    ✓ Actual fraud ratio: 8.82%
Total labeled samples: 640
Fraud in labeled: 40 samples (6.25%)
Remaining unlabeled: 181636

--- Iteration 6 ---
Validation - F1: 0.1039, Accuracy: 0.9746, Precision: 0.0553, Recall: 0.8481
  🎯 Using STRATIFIED random sampling (maintaining 10.0% fraud ratio)
    ✓ Selected 6 fraud + 62 non-fraud
    ✓ Actual fraud ratio: 8.82%
Total labeled samples: 708
Fraud in labeled: 46 samples (6.50%)
Remaining unlabeled: 181568

--- Iteration 7 ---
Validation - F1: 0.1089, Accuracy: 0.9759, Precision: 0.0582, Recall: 0.8481
  🎯 Using STRATIFIED random sampling (maintaining 10.0% fraud ratio)
    ✓ Selected 6 fraud + 62 non-fraud
    ✓ Actual fraud ratio: 8.82%
Total labeled samples: 776
Fraud in labeled: 52 samples (6.70%)
Remaining unlabeled: 181500

--- Iteration 8 ---
Validation - F1: 0.1219, Accuracy: 0.9788, Precision: 0.0657, Recall: 0.8481
  🎯 Using STRATIFIED random sampling (maintaining 10.0% fraud ratio)
    ✓ Selected 6 fraud + 62 non-fraud
    ✓ Actual fraud ratio: 8.82%
Total labeled samples: 844
Fraud in labeled: 58 samples (6.87%)
Remaining unlabeled: 181432

--- Iteration 9 ---
Validation - F1: 0.1092, Accuracy: 0.9753, Precision: 0.0582, Recall: 0.8734
  🎯 Using STRATIFIED random sampling (maintaining 10.0% fraud ratio)
    ✓ Selected 6 fraud + 62 non-fraud
    ✓ Actual fraud ratio: 8.82%
Total labeled samples: 912
Fraud in labeled: 64 samples (7.02%)
Remaining unlabeled: 181364

--- Iteration 10 ---
Validation - F1: 0.1037, Accuracy: 0.9738, Precision: 0.0551, Recall: 0.8734
  🎯 Using STRATIFIED random sampling (maintaining 10.0% fraud ratio)
    ✓ Selected 6 fraud + 62 non-fraud
    ✓ Actual fraud ratio: 8.82%
Total labeled samples: 980
Fraud in labeled: 70 samples (7.14%)
Remaining unlabeled: 181296

--- Iteration 11 ---
Validation - F1: 0.1087, Accuracy: 0.9752, Precision: 0.0579, Recall: 0.8734

--- Final Test Evaluation ---
Test Performance - F1: 0.1079, Accuracy: 0.9736, Precision: 0.0573, Recall: 0.9286

================================================================================
EXPERIMENTAL RESULTS COMPARISON
================================================================================
Active Learning F1: 0.6007
Passive Learning F1: 0.1079
F1 Improvement: 0.4928
Improvement %: 456.48%

📝 Experiment completed - Results demonstrate fair comparison methodology!
