ğŸ“ Logging started - Output will be saved to: /Users/lucasbraga/Documents/GitHub/active-learning/experimentation-fraud/data/logs/experiment_log_fraud_config_01_20250917_221724.txt
â° Timestamp: 2025-09-17 22:17:24
================================================================================
ğŸ’³ Credit Card Fraud Detection - Active Learning vs Passive Learning Comparison
================================================================================
Dataset: Kaggle European Credit Card Fraud Dataset
Target: Fraud detection (Class: 0=non-fraud, 1=fraud)
Features: Time, V1-V28 (anonymized), Amount
================================================================================
ğŸ¯ Implementation: Stratified passive learning maintains fraud representation
================================================================================
Model Configuration:
  Model Type: logistic

Plot Configuration:
  Show Plots: False

Experiment Configuration:
  Initial samples: 300
  Initial strategy: stratified
  Batch size: 68
  Iterations: 11
  Strategies: ['uncertainty', 'uncertainty', 'uncertainty', 'uncertainty', 'diversity', 'diversity', 'uncertainty', 'diversity', 'uncertainty', 'uncertainty', 'qbc']

âœ… Loading fraud dataset from: /Users/lucasbraga/Documents/GitHub/active-learning/active-learning/data/european-credit-card-dataset/creditcard.csv
Loading and splitting credit card fraud data...
Dataset shape: (284807, 31)
ğŸ§¹ Cleaning and preprocessing credit card fraud dataset...
  ğŸ“Š Original dataset shape: (284807, 31)
  ğŸ” Missing values in original data:
    No missing values found
  ğŸ¯ Target distribution: {0: 284315, 1: 492}
  âš ï¸  Fraud percentage: 0.173%
  âœ“ Added cyclical time features (hour of day)
  âœ“ Added log-transformed amount feature
  âœ“ Added amount bins for interpretability
  âœ“ One-hot encoded categorical features
  ğŸ” Checking for NaN values after preprocessing...
    âœ“ No NaN values found after preprocessing
  ğŸ”§ Applying feature standardization...
    ğŸ”’ Using sorted column order for reproducibility
    âœ“ Standardized 31 numerical features
    âœ“ Kept 6 categorical features unchanged (already 0/1)
  ğŸ“Š Final dataset shape: (284807, 37)
  ğŸ¯ Final target distribution: {0: 284315, 1: 492}
  ğŸ“‹ Feature columns: ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Time_hour_sin', 'Time_hour_cos', 'Amount_log', 'Amount_very_small', 'Amount_small', 'Amount_medium', 'Amount_large', 'Amount_very_large', 'Amount_extreme']
Features after preprocessing: 37
Label distribution: {0: 284315, 1: 492}
Train set: 227845 samples
Test set: 56962 samples
Label distribution in train: {0: 227451, 1: 394}
Label distribution in test: {0: 56864, 1: 98}

ğŸ§ª RUNNING STRATIFIED PASSIVE LEARNING EXPERIMENT

============================================================
ACTIVE LEARNING EXPERIMENT - FRAUD DETECTION
============================================================
  ğŸ¯ Creating stratified initial split with 300 samples...
    Available fraud samples: 315
    Available non-fraud samples: 181961
    âœ“ Selected 10 fraud + 290 non-fraud samples
    âœ“ Initial fraud percentage: 3.33%
Initial labeled pool: 300 samples
Initial fraud in labeled: 10 samples (3.33%)
Remaining unlabeled: 181976 samples

--- Iteration 1 ---
Validation - F1: 0.6936, Accuracy: 0.9988, Precision: 0.6383, Recall: 0.7595
Selected 68 samples using uncertainty sampling
Total labeled samples: 368
Fraud in labeled: 10 samples (2.72%)
Remaining unlabeled: 181908

--- Iteration 2 ---
Validation - F1: 0.7947, Accuracy: 0.9993, Precision: 0.8333, Recall: 0.7595
Selected 68 samples using uncertainty sampling
Total labeled samples: 436
Fraud in labeled: 10 samples (2.29%)
Remaining unlabeled: 181840

--- Iteration 3 ---
Validation - F1: 0.7947, Accuracy: 0.9993, Precision: 0.8333, Recall: 0.7595
Selected 68 samples using uncertainty sampling
Total labeled samples: 504
Fraud in labeled: 11 samples (2.18%)
Remaining unlabeled: 181772

--- Iteration 4 ---
Validation - F1: 0.2367, Accuracy: 0.9905, Precision: 0.1376, Recall: 0.8481
Selected 68 samples using uncertainty sampling
Total labeled samples: 572
Fraud in labeled: 11 samples (1.92%)
Remaining unlabeled: 181704

--- Iteration 5 ---
Validation - F1: 0.6220, Accuracy: 0.9983, Precision: 0.5000, Recall: 0.8228
Selected 68 samples using diversity sampling
Total labeled samples: 640
Fraud in labeled: 20 samples (3.12%)
Remaining unlabeled: 181636

--- Iteration 6 ---
Validation - F1: 0.7711, Accuracy: 0.9992, Precision: 0.7356, Recall: 0.8101
Selected 68 samples using diversity sampling
Total labeled samples: 708
Fraud in labeled: 26 samples (3.67%)
Remaining unlabeled: 181568

--- Iteration 7 ---
Validation - F1: 0.7901, Accuracy: 0.9993, Precision: 0.7711, Recall: 0.8101
Selected 68 samples using uncertainty sampling
Total labeled samples: 776
Fraud in labeled: 34 samples (4.38%)
Remaining unlabeled: 181500

--- Iteration 8 ---
Validation - F1: 0.3785, Accuracy: 0.9952, Precision: 0.2436, Recall: 0.8481
Selected 68 samples using diversity sampling
Total labeled samples: 844
Fraud in labeled: 41 samples (4.86%)
Remaining unlabeled: 181432

--- Iteration 9 ---
Validation - F1: 0.4012, Accuracy: 0.9956, Precision: 0.2627, Recall: 0.8481
Selected 68 samples using uncertainty sampling
Total labeled samples: 912
Fraud in labeled: 41 samples (4.50%)
Remaining unlabeled: 181364

--- Iteration 10 ---
Validation - F1: 0.5197, Accuracy: 0.9973, Precision: 0.3771, Recall: 0.8354
Selected 68 samples using uncertainty sampling
Total labeled samples: 980
Fraud in labeled: 42 samples (4.29%)
Remaining unlabeled: 181296

--- Iteration 11 ---
Validation - F1: 0.6377, Accuracy: 0.9984, Precision: 0.5156, Recall: 0.8354

--- Final Test Evaluation ---
Test Performance - F1: 0.6007, Accuracy: 0.9980, Precision: 0.4595, Recall: 0.8673

============================================================
PASSIVE LEARNING EXPERIMENT - FRAUD DETECTION
============================================================
  ğŸ¯ Creating stratified initial split with 300 samples...
    Available fraud samples: 315
    Available non-fraud samples: 181961
    âœ“ Selected 10 fraud + 290 non-fraud samples
    âœ“ Initial fraud percentage: 3.33%
Initial labeled pool: 300 samples
Initial fraud in labeled: 10 samples (3.33%)
Remaining unlabeled: 181976 samples
ğŸ¯ Using stratified passive sampling

--- Iteration 1 ---
Validation - F1: 0.6936, Accuracy: 0.9988, Precision: 0.6383, Recall: 0.7595
  ğŸ¯ Using STRATIFIED random sampling (maintaining 10.0% fraud ratio)
    âœ“ Selected 6 fraud + 62 non-fraud
    âœ“ Actual fraud ratio: 8.82%
Total labeled samples: 368
Fraud in labeled: 16 samples (4.35%)
Remaining unlabeled: 181908

--- Iteration 2 ---
Validation - F1: 0.1570, Accuracy: 0.9856, Precision: 0.0874, Recall: 0.7722
  ğŸ¯ Using STRATIFIED random sampling (maintaining 10.0% fraud ratio)
    âœ“ Selected 6 fraud + 62 non-fraud
    âœ“ Actual fraud ratio: 8.82%
Total labeled samples: 436
Fraud in labeled: 22 samples (5.05%)
Remaining unlabeled: 181840

--- Iteration 3 ---
Validation - F1: 0.1387, Accuracy: 0.9823, Precision: 0.0758, Recall: 0.8228
  ğŸ¯ Using STRATIFIED random sampling (maintaining 10.0% fraud ratio)
    âœ“ Selected 6 fraud + 62 non-fraud
    âœ“ Actual fraud ratio: 8.82%
Total labeled samples: 504
Fraud in labeled: 28 samples (5.56%)
Remaining unlabeled: 181772

--- Iteration 4 ---
Validation - F1: 0.0792, Accuracy: 0.9648, Precision: 0.0415, Recall: 0.8734
  ğŸ¯ Using STRATIFIED random sampling (maintaining 10.0% fraud ratio)
    âœ“ Selected 6 fraud + 62 non-fraud
    âœ“ Actual fraud ratio: 8.82%
Total labeled samples: 572
Fraud in labeled: 34 samples (5.94%)
Remaining unlabeled: 181704

--- Iteration 5 ---
Validation - F1: 0.0821, Accuracy: 0.9671, Precision: 0.0431, Recall: 0.8481
  ğŸ¯ Using STRATIFIED random sampling (maintaining 10.0% fraud ratio)
    âœ“ Selected 6 fraud + 62 non-fraud
    âœ“ Actual fraud ratio: 8.82%
Total labeled samples: 640
Fraud in labeled: 40 samples (6.25%)
Remaining unlabeled: 181636

--- Iteration 6 ---
Validation - F1: 0.1039, Accuracy: 0.9746, Precision: 0.0553, Recall: 0.8481
  ğŸ¯ Using STRATIFIED random sampling (maintaining 10.0% fraud ratio)
    âœ“ Selected 6 fraud + 62 non-fraud
    âœ“ Actual fraud ratio: 8.82%
Total labeled samples: 708
Fraud in labeled: 46 samples (6.50%)
Remaining unlabeled: 181568

--- Iteration 7 ---
Validation - F1: 0.1089, Accuracy: 0.9759, Precision: 0.0582, Recall: 0.8481
  ğŸ¯ Using STRATIFIED random sampling (maintaining 10.0% fraud ratio)
    âœ“ Selected 6 fraud + 62 non-fraud
    âœ“ Actual fraud ratio: 8.82%
Total labeled samples: 776
Fraud in labeled: 52 samples (6.70%)
Remaining unlabeled: 181500

--- Iteration 8 ---
Validation - F1: 0.1219, Accuracy: 0.9788, Precision: 0.0657, Recall: 0.8481
  ğŸ¯ Using STRATIFIED random sampling (maintaining 10.0% fraud ratio)
    âœ“ Selected 6 fraud + 62 non-fraud
    âœ“ Actual fraud ratio: 8.82%
Total labeled samples: 844
Fraud in labeled: 58 samples (6.87%)
Remaining unlabeled: 181432

--- Iteration 9 ---
Validation - F1: 0.1092, Accuracy: 0.9753, Precision: 0.0582, Recall: 0.8734
  ğŸ¯ Using STRATIFIED random sampling (maintaining 10.0% fraud ratio)
    âœ“ Selected 6 fraud + 62 non-fraud
    âœ“ Actual fraud ratio: 8.82%
Total labeled samples: 912
Fraud in labeled: 64 samples (7.02%)
Remaining unlabeled: 181364

--- Iteration 10 ---
Validation - F1: 0.1037, Accuracy: 0.9738, Precision: 0.0551, Recall: 0.8734
  ğŸ¯ Using STRATIFIED random sampling (maintaining 10.0% fraud ratio)
    âœ“ Selected 6 fraud + 62 non-fraud
    âœ“ Actual fraud ratio: 8.82%
Total labeled samples: 980
Fraud in labeled: 70 samples (7.14%)
Remaining unlabeled: 181296

--- Iteration 11 ---
Validation - F1: 0.1087, Accuracy: 0.9752, Precision: 0.0579, Recall: 0.8734

--- Final Test Evaluation ---
Test Performance - F1: 0.1079, Accuracy: 0.9736, Precision: 0.0573, Recall: 0.9286

================================================================================
EXPERIMENTAL RESULTS COMPARISON
================================================================================
Active Learning F1: 0.6007
Passive Learning F1: 0.1079
F1 Improvement: 0.4928
Improvement %: 456.48%

ğŸ“ Experiment completed - Results demonstrate fair comparison methodology!
